{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global image directory path\n",
    "IMG_DIR = \"/Users/susanketsarkar/Desktop/Code/Meesho/data/train_images\"  # Update with your image directory\n",
    "\n",
    "def load_data(csv_path, attr_to_predict):\n",
    "    # Load data\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Extract relevant columns\n",
    "    df = df[['id', 'Category', attr_to_predict]]\n",
    "    \n",
    "    # Drop rows with missing values in the target attribute\n",
    "    df.dropna(subset=[attr_to_predict], inplace=True)\n",
    "\n",
    "    # Create image paths\n",
    "    df['image_path'] = df['id'].apply(lambda x: os.path.join(IMG_DIR, f\"{str(x).zfill(6)}.jpg\"))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def preprocess_images(image_paths, target_size=(64, 64)):\n",
    "    images = []\n",
    "    for img_path in image_paths:\n",
    "        if os.path.exists(img_path):\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.resize(img, target_size)\n",
    "            images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "def build_cnn_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_cnn_on_attribute(csv_path, attr_to_predict, epochs=10):\n",
    "    # Load and prepare data\n",
    "    df = load_data(csv_path, attr_to_predict)\n",
    "    X = preprocess_images(df['image_path'].tolist())\n",
    "\n",
    "    print(f\"Training on {len(X)} data points...\")\n",
    "    \n",
    "    # Encode labels\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(df[attr_to_predict])\n",
    "    y = to_categorical(y)\n",
    "    \n",
    "    # Split the dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Build CNN model\n",
    "    print(\"Building the model...\")\n",
    "    model = build_cnn_model(input_shape=(64, 64, 3), num_classes=y.shape[1])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=4, validation_split=0.1, verbose=2)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(f\"Generating the metrics...\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # Print metrics\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred_classes, target_names=le.classes_))\n",
    "    print(f\"Accuracy: {accuracy_score(y_true, y_pred_classes) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 6629 data points...\n",
      "Building the model...\n",
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"../data/cat_wise_csv/Kurtis_data.csv\"  # Replace with your actual CSV path\n",
    "attr_to_predict = 'color'  # Change this to the desired attribute\n",
    "train_cnn_on_attribute(csv_path, attr_to_predict, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
