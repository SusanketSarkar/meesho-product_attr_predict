{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms, models\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# if torch.backends.mps.is_available():\n",
    "#     mps_device = torch.device(\"mps\")\n",
    "#     x = torch.ones(1, device=mps_device)\n",
    "#     print (x)\n",
    "# else:\n",
    "#     print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global image directory path\n",
    "IMG_DIR = \"/Users/susanketsarkar/Desktop/Code/Meesho/data/train_images\"  # Update with your image directory\n",
    "\n",
    "class CenterCropWithMargin:\n",
    "    def __init__(self, margin_percent=0.1):\n",
    "        self.margin_percent = margin_percent\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        # Calculate the cropping dimensions\n",
    "        width, height = img.size\n",
    "        crop_margin_w = int(width * self.margin_percent)\n",
    "        crop_margin_h = int(height * self.margin_percent)\n",
    "        \n",
    "        # Crop the image by removing the calculated margin from each side\n",
    "        cropped_img = img.crop((\n",
    "            crop_margin_w, crop_margin_h,\n",
    "            width - crop_margin_w, height - crop_margin_h\n",
    "        ))\n",
    "        return cropped_img\n",
    "    \n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.dataframe.iloc[idx]['image_path']\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = self.dataframe.iloc[idx]['label']\n",
    "        return image, label\n",
    "\n",
    "def load_data(csv_path, attr_to_predict):\n",
    "    # Load data\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Extract relevant columns\n",
    "    df = df[['id', 'Category', attr_to_predict]]\n",
    "    l1 = len(df)\n",
    "    \n",
    "    # Drop rows with missing values in the target attribute\n",
    "    df.dropna(subset=[attr_to_predict], inplace=True)\n",
    "    print(\"Number of nan objects: \", l1-len(df))\n",
    "\n",
    "    # Create image paths\n",
    "    df['image_path'] = df['id'].apply(lambda x: os.path.join(IMG_DIR, f\"{str(x).zfill(6)}.jpg\"))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def preprocess_data(df, attr_to_predict):\n",
    "    # Encode labels\n",
    "    le = LabelEncoder()\n",
    "    df['label'] = le.fit_transform(df[attr_to_predict])\n",
    "    \n",
    "    return df, le\n",
    "\n",
    "def build_cnn_model(num_classes):\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        \n",
    "        nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        \n",
    "        nn.Flatten(),\n",
    "        nn.Linear(64 * 16 * 16, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(128, num_classes)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_cnn_on_attribute(csv_path, attr_to_predict, epochs=10, batch_size=4):\n",
    "    # Load and prepare data\n",
    "    df = load_data(csv_path, attr_to_predict)\n",
    "    df, le = preprocess_data(df, attr_to_predict)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        CenterCropWithMargin(margin_percent=0.1),\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "    dataset = CustomImageDataset(dataframe=df, transform=transform)\n",
    "    \n",
    "    # Split the dataset\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Build CNN model\n",
    "    print(\"Building the model...\")\n",
    "    model = build_cnn_model(num_classes=len(le.classes_))\n",
    "    \n",
    "    # Move model to GPU if available\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the model\n",
    "    print(f\"Training the model on {train_size} data points...\")\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch} running...\")\n",
    "        for images, labels in tqdm.tqdm(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(\"Evaluating the model...\")\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "\n",
    "    # Print metrics\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=le.classes_))\n",
    "    print(f\"Accuracy: {accuracy_score(all_labels, all_preds) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nan objects:  4946\n",
      "Building the model...\n",
      "Training the model on 11246 data points...\n",
      "Epoch 0 running...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [00:45<00:00,  7.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 running...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [00:47<00:00,  7.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 running...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [01:02<00:00,  5.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 running...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [00:41<00:00,  8.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 running...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [00:49<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 running...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [00:45<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 running...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [00:48<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 running...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [00:39<00:00,  8.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 running...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [00:46<00:00,  7.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 running...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [00:50<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model...\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       black       0.87      0.89      0.88       538\n",
      "        blue       0.67      0.77      0.72       201\n",
      "     default       0.66      0.65      0.66       397\n",
      "       green       0.75      0.79      0.77       144\n",
      "      maroon       0.84      0.76      0.80       154\n",
      "  multicolor       0.46      0.14      0.22        84\n",
      "   navy blue       0.72      0.71      0.72        87\n",
      "       peach       0.62      0.31      0.41        74\n",
      "        pink       0.77      0.82      0.79       327\n",
      "         red       0.77      0.91      0.84       140\n",
      "       white       0.86      0.86      0.86       482\n",
      "      yellow       0.74      0.82      0.78       184\n",
      "\n",
      "    accuracy                           0.78      2812\n",
      "   macro avg       0.73      0.70      0.70      2812\n",
      "weighted avg       0.77      0.78      0.77      2812\n",
      "\n",
      "Accuracy: 77.60%\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"../data/cat_wise_csv/Women_Tops_&_Tunics_data.csv\"  \n",
    "attr_to_predict = 'color'  \n",
    "train_cnn_on_attribute(csv_path, attr_to_predict, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoded CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DIR = \"/Users/susanketsarkar/Desktop/Code/Meesho/data/train_images\"  # Update with your image directory\n",
    "\n",
    "# Custom dataset to handle the images and attributes\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.dataframe.iloc[idx]['image_path']  # Adjust according to your image path column\n",
    "        image = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)  # Open image and convert to RGB\n",
    "        attributes = self.dataframe.columns[3:]  # Assuming first three columns are id, Category, and len\n",
    "        unique_classes = {attr: self.dataframe[attr].unique() for attr in attributes}\n",
    "        num_attributes = len(unique_classes)\n",
    "        max_classes = max(len(v) for v in unique_classes.values())\n",
    "\n",
    "        # Create a mapping from attributes to class indices\n",
    "        mlb = MultiLabelBinarizer()\n",
    "        binary_labels = mlb.fit_transform(self.dataframe[attributes].values)  # Get attribute values\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(binary_labels)\n",
    "\n",
    "def load_data(csv_path, attrs_to_predict:List):\n",
    "    # Load data\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Extract relevant columns\n",
    "    # df = df[['id', 'Category'].extend(list(attrs_to_predict))]\n",
    "    df.drop([\"len\"], axis=1, inplace=True)\n",
    "    l1 = len(df)\n",
    "    \n",
    "    # Drop rows with missing values in the target attribute\n",
    "    # df.dropna(subset=[attr_to_predict], inplace=True)\n",
    "    # print(\"Number of nan objects: \", l1-len(df))\n",
    "\n",
    "    # Create image paths\n",
    "    df['image_path'] = df['id'].apply(lambda x: os.path.join(IMG_DIR, f\"{str(x).zfill(6)}.jpg\"))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function to build the ResNet model\n",
    "def build_resnet_model(num_attributes, max_classes):\n",
    "    resnet = models.resnet50(pretrained=True)\n",
    "    num_ftrs = resnet.fc.in_features\n",
    "\n",
    "    # Change the final layer to output n x m (n = num_attributes, m = max_classes)\n",
    "    resnet.fc = nn.Linear(num_ftrs, num_attributes * max_classes)\n",
    "    \n",
    "    return resnet\n",
    "\n",
    "# Function to prepare data and train the model\n",
    "def train_resnet_on_attributes(csv_path, img_dir, category, epochs=10, batch_size=32):\n",
    "    # Load the data\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df = load_data(csv_path, df.columns[3:])\n",
    "    \n",
    "    # Filter the dataframe for the given category\n",
    "    # df = df[df['Category'] == category].reset_index(drop=True)\n",
    "    \n",
    "    # Get unique classes for each attribute\n",
    "    attributes = df.columns[3:]  # Assuming first three columns are id, Category, and len\n",
    "    unique_classes = {attr: df[attr].unique() for attr in attributes}\n",
    "    num_attributes = len(unique_classes)\n",
    "    max_classes = max(len(v) for v in unique_classes.values())\n",
    "\n",
    "    # Create a mapping from attributes to class indices\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    binary_labels = mlb.fit_transform(df[attributes].values)\n",
    "    \n",
    "    # Transformations for the images\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    # Create the dataset and dataloaders\n",
    "    dataset = CustomImageDataset(dataframe=df, transform=transform)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Build and train the model\n",
    "    model = build_resnet_model(num_attributes, max_classes)\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        for images, labels in tqdm.tqdm(train_loader):\n",
    "            print(images.shape, labels.shape)\n",
    "            images = images.to(device)\n",
    "            labels = torch.FloatTensor(labels).to(device)  # Convert labels to FloatTensor\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = torch.FloatTensor(labels).to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            preds = torch.sigmoid(outputs).cpu().numpy() > 0.5  # Apply sigmoid and threshold\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    all_preds = np.vstack(all_preds)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "\n",
    "    # Print classification report for each attribute\n",
    "    print(\"Classification Report:\")\n",
    "    for i, attr in enumerate(attributes):\n",
    "        print(f\"\\nAttribute: {attr}\")\n",
    "        print(classification_report(all_labels[:, i], all_preds[:, i]))\n",
    "\n",
    "    # Save the model\n",
    "    model_save_path = f\"{category}_resnet_model.pth\"\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/182 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "csv_path = \"../data/filled_data/Men_Tshirts_data.csv\"  # Path to your CSV\n",
    "img_dir = \"../data/train_images\"      # Directory containing images\n",
    "category_to_predict = \"Men_Tshirts\"        # Category to train on\n",
    "\n",
    "train_resnet_on_attributes(csv_path, img_dir, category_to_predict, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
